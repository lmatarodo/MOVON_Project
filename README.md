본 프로젝트의 결과물은 운전자의 얼굴 인식을 통한 눈감김 감지, 차선 이탈 감지, 그리고 이를 종합한 졸음 운전 판단  및 경고 시스템으로 구성된다.
 먼저 운전자의 졸음 상태를 실시간으로 감지하기 위해 얼굴 인식 기반의 눈 감김 감지 알고리즘을 구현하였다. 차량 내부의 운전자 전방에 설치된 카메라를 대신하여 본 프로젝트에서는 노트북의 웹캠으로 대체하였다. 영상 처리에서 조명은 객체 검출 성능에 많은 영향을 미치기 때문에, 조명의 영향을 최소화하기 위해 Light Preprocessing 과정을 거친다. 그리고 HOG(Histogram of Oriented Gradients) 기반 얼굴 검출 기법을 활용하여 얼굴 영역을 식별한 후, Face Landmark Estimation을 통해 68개의 얼굴 랜드마크를 추출한다. 그중 눈 주위의 특정 여섯 개 지점을 이용하여 EAR(Eye Aspect Ratio)을 계산하며, EAR 값이 일정 임계값 이하로 떨어지면 눈이 감긴 상태로 판단한다. EAR 값이 임계값보다 낮은 상태가 5초 이상 지속될 경우 졸음운전으로 간주하며, 즉각적으로 경보음을 전송한다. 아두이노 모듈을 활용하여 부저를 작동시키며, 졸음 상태가 지속될수록 부저의 주파수를 증가시켜 점점 더 강한 경고음을 발생시키는 방식으로 운전자의 주의를 환기시킨다. 이를 통해 운전자가 졸음 상태에서 빠르게 인지하고 대응할 수 있도록 설계하였다.

 
차선 이탈 감지는 미리 녹화된 도로 주행 영상을 입력받아 YOLOPv2 모델을 활용하여 수행된다. YOLOPv2는 객체 탐지와 차선 세그멘테이션을 동시에 수행할 수 있는 딥러닝 모델로, 본 프로젝트에서는 차선 검출 기능을 활용하여 차량이 차선을 벗어나는지를 분석한다. 차선 검출 과정에서 YOLOPv2를 통해 생성된 차선 마스크를 Binary Thresholding하여 차선 영역을 흰색(255), 나머지 영역을 검은색(0)으로 변환한 후, Perspective Transformation을 적용하여 Top View 형태로 변환한다. 이렇게 변환된 영상에서 차량의 위치를 고려하여 ROI(Region of Interest)를 설정하고, 해당 영역 내의 차선 픽셀 개수를 분석하여 차선 이탈 여부를 판단한다. 일정 임계값 이하로 차선 픽셀이 검출되면 차량이 차선을 벗어났다고 판단하며, 노이즈나 일시적인 오차로 인해 잘못된 감지가 발생하지 않도록 일정 시간 연속적으로 차선 이탈이 감지될 경우에만 최종적으로 경고를 발생시키도록 설계하였다.
 최종적으로, 운전자의 눈감김 감지와 차선 이탈 감지의 두 가지 요소를 종합적으로 분석하여 보다 정밀한 경고 시스템을 구현하였다. 운전자가 깜빡이를 켜고 정상적으로 차선 변경을 수행할 수도 있기 때문에, 단순히 차선 이탈이 감지되었을 경우에는 경보음을 발생하지 않으며 초록색 LED가 켜진다. 하지만 운전자의 눈감김이 5초 이상 지속, 즉 운전자가 졸음 운전 상태로 판단되며 동시에 차선 이탈이 감지될 경우에는 즉각적인 경고가 필요하므로 강한 경보음과 함께 빨간색 LED가 점등된다.
 본 프로젝트의 결과물은 조명 변화에도 정상적으로 얼굴을 인식할 수 있도록 Light Preprocessing을 적용하여 다양한 환경에서 안정적인 졸음 감지를 수행할 수 있으며, 차선 검출 과정에서 투시 변환과 ROI 기반 분석을 적용하여 차선 이탈 감지 정확도를 향상시켰다. 또한, 졸음 감지와 차선 이탈 감지를 연계함으로써 보다 정교한 운전 보조 시스템을 개발하였으며, 이를 통해 졸음운전으로 인한 사고를 예방하고 보다 안전한 운전 환경을 조성할 수 있도록 설계되었다.
